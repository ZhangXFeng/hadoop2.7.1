Hadoop源码环境搭建,强烈建议使用linux/mac系统

安装maven
安装git
安装protoc，版本2.5.0
安装Eclipse
下载hadoop源码，git clone https://github.com/apache/hadoop.git
进入到源码的hadoop-maven-plugins目录，执行mvn install
设置环境变量HADOOP_PROTOC_PATH，该环境变量是protoc命令的目录，hadoop源码编译的时候会使用protoc编译proto文件，hadoop内部RPC机制使用了google的protobuf框架
进入hadoop源码的src目录，执行mvn compile -X
打开Eclipse，设置Eclipse的maven配置，然后点击File->Import->Existing Maven Projects，选着hadoop源码目录，然后单击Finish导入hadoop项目



源码工程大致讲解

hadoop项目分4个子模块：Hadoop common、HDFS、MapReduce、Yarn，每个子模块又包含了多个子工程。

调试源码
调试源码首先需要找到程序的入口。程序的入口在各个项目的启动脚本里，hdfs的启动脚本是hdfs，yarn的启动脚本是yarn，MapReduce的启动脚本是mapred。

HDFS: 从hdfs启动脚本里可以看到NameNode(NN)的入口类是org.apache.hadoop.hdfs.server.namenode.NameNode，DataNode(DN)的入口类是org.apache.hadoop.hdfs.server.datanode.DataNode，JournalNode(JN)的入口类是org.apache.hadoop.hdfs.qjournal.server.JournalNode，zkfc的入口类是org.apache.hadoop.hdfs.tools.DFSZKFailoverController。NN、DN、JN和ZKFC是一个高可用HDFS集群的基本服务。

Yarn: 从yarn启动基本里可以看到ResourceManager(RM)的入口类是org.apache.hadoop.yarn.server.resourcemanager.ResourceManager，NodeManager(NM)的入口类是org.apache.hadoop.yarn.server.nodemanager.NodeManager。

MapReduce: 从MRv2开始，MR框架没有类似JobTracker、TaskTracker这样的常驻服务了，只有一个JobHistoryServer，因此mapred脚本里也只是包含了一个启动historyserver的功能，入口类是org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer。

怎么看MapReduce源码

了解MRv2的一个大致运行流程。调试WordCount程序，掌握MRv2的提交流程
了解了MRv2的提交流程后，可以知道提交程序是向RM申请了一个Container，该Container作为运行MR ApplicationMaster的容器；看完MRv2的提交流程，我们还可以知道MRv2的ApplicationMaster对应的是org.apache.hadoop.mapreduce.v2.app.MRAppMaster类
从MRAppMaster类的main方法一路读下去，我们可以发现map/reduce对应的类是YarnChild，因此当想看map/reduce的执行逻辑时可以看YarnChild的实现。YarnChild内部用了一个叫MapTask的类封装了map任务，一个叫ReduceTask的类封装了reduce任务；具体的map/reduce执行逻辑可以查看map/reduce中的run方法


怎样写MR程序

InputFormat
OutputFormat
RecordReader
RecordWriter
Partitioner
InputSplit
Mapper
Reducer

InputFormat：需要实现getSplits和getRecordReader方法。getSplits方法返回InputSplit的链表，返回多少个InputSplit就会起多少个map任务；getRecordReader方法返回一个RecordReader的对象，RecordReader对象提供map任务的输入，包括key和value。getSplits方法在客户端提交程序中执行，getRecordReader方法在map任务中执行。默认的InputFormat是TextInputFormat。

RecordReader：RecordReader提供map任务的输入。nextKeyValue方法读取下一个key和value的值，返回false表示所有数据已经读取完了；返回true表示这一次调用读到了新的key和value，map任务并没有结束。getCurrentKey方法返回当前读到的key，getCurrentValue返回当前读到的value，getProgress方法返回当前的进度，close方法里可以做一些善后操作，比如关闭数据库连接、关闭输入流等。需要在InputFormat的getRecordReader方法里返回我们自己实现的RecordReader对象。默认的RecordReader是LineRecordReader。

InputSplit：InputSplit表示对于输入数据的分片，比如我们想处理HDFS上多个目录的数据，设想是一个目录的数据用一个map来处理，那么这里的一个目录就对应一个InputSplit。假如有n个目录，我们就需要在InputSplit的getSplits方法里返回一个包含n个InputSplit的链表。实现一个InputSplit需要实现InputSplit和Writable接口。值得注意的是，必须实现一个不带参数的构造方法和一个不返回null的getLocations方法，因为MR框架会采用反射调用InputSplit的无参构造方法以及会调用getLocations.length方法。另外根据需要，我们可以实现readFields和write方法，因为分片信息都是序列化到hdfs上，map任务运行时从hdfs上取下来再反序列化出来的。默认的InputSplit是FileSplit。

OutputFormat：自定义OutputFormat需要实现getRecordWriter和checkOutputSpecs方法。checkOutputSpecs方法做一些无关痛痒的检查操作，可以根据具体的业务考虑是否做一些特殊的检查；getRecordWriter方法返回一个RecordWriter对象。默认的OutputFormat是TextOutputFormat。

Partitioner：Partitioner作用在map任务的输出阶段，实现一个自定义的Partitioner需要继承Partitioner类，并且实现getPartition方法。该方法决定了map阶段输出的数据将被哪个reduce任务处理。

RecordWriter：实现RecordWriter需要实现write和close方法。当在mapper/reducer中的map/reduce方法中调用context的write方法时，MR框架会调用RecordWriter的write方法将key和value写到外部，具体的write逻辑就可以在write方法中实现。close方法是做一个善后操作的地方，比如我们可以在write方法中将key和value写入到HDFS，在close方法中实现关闭数据流的逻辑。默认的RecordWriter是LineRecordWriter.

Mapper：实现自定义的Mapper需要继承Mapper类。Mapper类有三个方法：setup、map和cleanup。setup方法中可以做一些初始化的操作，map方法中对从RecordReader中读取的key和value做处理，cleanup方法中做一些善后操作。map任务运行时的核心逻辑就是调用Mapper的run方法，不断的对读取到的key和value做处理。下面是Mapper的run方法实现：



Reducer：事项自定义的Reducer需要继承Reducer类。Reducer类有三个方法：setup、reduce和cleanup。setup和cleanup方法的功能同Mapper中setup、cleanup一样，reduce方法将map端相同的key聚合在一起处理。下面是Reducer的run方法的实现：



